{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07cb596",
   "metadata": {},
   "source": [
    "Gaurav Dawar\n",
    "\n",
    "19BAI10174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55192040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b79d8",
   "metadata": {},
   "source": [
    "Pre processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e47e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_data=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb702b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 10 classes.\n",
      "Found 50 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_data.flow_from_directory(r\"/home/DELL/Downloads/dataset_hand_digit/traindata\",target_size=(96,96),batch_size=10,class_mode=\"categorical\")\n",
    "x_test=test_data.flow_from_directory(r\"/home/DELL/Downloads/dataset_hand_digit/testdata\",target_size=(96,96),batch_size=10,class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ca2fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f093ee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af44a276",
   "metadata": {},
   "source": [
    "model formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00589891",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(96,96,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=150,activation=\"relu\"))\n",
    "model.add(Dense(units=10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deceba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 94, 94, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 47, 47, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 70688)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 150)               10603350  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1510      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,605,756\n",
      "Trainable params: 10,605,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c37611d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae4f265",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50f18810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 2s 118ms/step - loss: 10.2316 - accuracy: 0.0812 - val_loss: 2.9625 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 2s 115ms/step - loss: 2.5175 - accuracy: 0.1125 - val_loss: 2.3050 - val_accuracy: 0.1400\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 2s 107ms/step - loss: 2.2671 - accuracy: 0.1375 - val_loss: 2.2060 - val_accuracy: 0.2000\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 2s 109ms/step - loss: 2.1168 - accuracy: 0.2937 - val_loss: 2.1036 - val_accuracy: 0.2400\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 1.9604 - accuracy: 0.3313 - val_loss: 2.0348 - val_accuracy: 0.2200\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 2s 108ms/step - loss: 1.8230 - accuracy: 0.3812 - val_loss: 1.8967 - val_accuracy: 0.3600\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 1.6571 - accuracy: 0.4500 - val_loss: 1.7962 - val_accuracy: 0.3800\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 1.4338 - accuracy: 0.5625 - val_loss: 1.6697 - val_accuracy: 0.4200\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 1.4028 - accuracy: 0.6000 - val_loss: 1.6725 - val_accuracy: 0.4200\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 2s 100ms/step - loss: 1.1837 - accuracy: 0.6438 - val_loss: 1.4927 - val_accuracy: 0.4400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff52a28ef10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,steps_per_epoch=16,epochs=10,validation_steps=5,validation_data=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c01261",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"assignment3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89106979",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea52a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2886197",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"assignment3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78b3ac76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96, 96, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img(r\"/home/harshit/Downloads/dataset_hand_digit/sample1.png\",target_size=(96,96))\n",
    "s1=image.img_to_array(img)\n",
    "s1=np.expand_dims(s1,axis=0)\n",
    "s1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7cb9e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAIAAABt+uBvAAAA40lEQVR4nO3cQQ3AQBDDwNvy53xFUPnZfcwgiAwgc+89fHv+HrCdQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAp7A83M3xPO2RxoCYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQGFvoCUns3sDLSFQECgIFAQKAgWBgkBBoCBQECgIFAQKAgWBgkBBoCBQECi8tLsGvfnJtsYAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96 at 0x7FF4EDEE3790>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=[0,1,2,3,4,5,6,7,8,9]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf8c6439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(Prediction): 1\n"
     ]
    }
   ],
   "source": [
    "result=index[np.argmax(model.predict(s1),axis=1)[0]]\n",
    "print(\"Result(Prediction):\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63c6cd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=96x96 at 0x7FF4EDF21AC0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img=image.load_img(\"/home/harshit/Downloads/dataset_hand_digit/sample6.png\",target_size=(96,96))\n",
    "s2=image.img_to_array(img)\n",
    "s2=np.expand_dims(s2,axis=0)\n",
    "#s2.shape\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d3df8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(Prediction): 6\n"
     ]
    }
   ],
   "source": [
    "result=index[np.argmax(model.predict(s2),axis=1)[0]]\n",
    "print(\"Result(Prediction):\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2975ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
